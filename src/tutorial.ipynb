{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arthurflor23/handwritten-text-recognition/blob/master/src/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "gP-v0E_S-mQP"
   },
   "source": [
    "<img src=\"https://github.com/arthurflor23/handwritten-text-recognition/blob/master/doc/image/header.png?raw=true\" />\n",
    "\n",
    "# Handwritten Text Recognition using TensorFlow 2.0\n",
    "\n",
    "This tutorial shows how you can use the project [Handwritten Text Recognition](https://github.com/arthurflor23/handwritten-text-recognition) in your Google Colab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "oMty1YwuWHpN"
   },
   "source": [
    "## 1 Localhost Environment\n",
    "\n",
    "We'll make sure you have the project in your Google Drive with the datasets in HDF5. If you already have structured files in the cloud, skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "39blvPTPQJpt"
   },
   "source": [
    "### 1.1 Datasets\n",
    "\n",
    "The datasets that you can use:\n",
    "\n",
    "a. [Bentham](http://transcriptorium.eu/datasets/bentham-collection/)\n",
    "\n",
    "b. [IAM](http://www.fki.inf.unibe.ch/databases/iam-handwriting-database)\n",
    "\n",
    "c. [Rimes](http://www.a2ialab.com/doku.php?id=rimes_database:start)\n",
    "\n",
    "d. [Saint Gall](http://www.fki.inf.unibe.ch/databases/iam-historical-document-database/saint-gall-database)\n",
    "\n",
    "e. [Washington](http://www.fki.inf.unibe.ch/databases/iam-historical-document-database/washington-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "QVBGMLifWQwl"
   },
   "source": [
    "### 1.2 Raw folder\n",
    "\n",
    "On localhost, download the code project from GitHub and extract the chosen dataset (or all if you prefer) in the **raw** folder. Don't change anything of the structure of the dataset, since the scripts were made from the **original structure** of them. Your project directory will be like this:\n",
    "\n",
    "```\n",
    ".\n",
    "├── raw\n",
    "│   ├── bentham\n",
    "│   │   ├── BenthamDatasetR0-GT\n",
    "│   │   └── BenthamDatasetR0-Images\n",
    "│   ├── iam\n",
    "│   │   ├── ascii\n",
    "│   │   ├── forms\n",
    "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
    "│   │   ├── lines\n",
    "│   │   └── xml\n",
    "│   ├── rimes\n",
    "│   │   ├── eval_2011\n",
    "│   │   ├── eval_2011_annotated.xml\n",
    "│   │   ├── training_2011\n",
    "│   │   └── training_2011.xml\n",
    "│   ├── saintgall\n",
    "│   │   ├── data\n",
    "│   │   ├── ground_truth\n",
    "│   │   ├── README.txt\n",
    "│   │   └── sets\n",
    "│   └── washington\n",
    "│       ├── data\n",
    "│       ├── ground_truth\n",
    "│       ├── README.txt\n",
    "│       └── sets\n",
    "└── src\n",
    "    ├── data\n",
    "    │   ├── evaluation.py\n",
    "    │   ├── generator.py\n",
    "    │   ├── preproc.py\n",
    "    │   ├── reader.py\n",
    "    │   ├── similar_error_analysis.py\n",
    "    ├── main.py\n",
    "    ├── network\n",
    "    │   ├── architecture.py\n",
    "    │   ├── layers.py\n",
    "    │   ├── model.py\n",
    "    └── tutorial.ipynb\n",
    "\n",
    "```\n",
    "\n",
    "After that, create virtual environment and install the dependencies with python 3 and pip:\n",
    "\n",
    "> ```python -m venv .venv && source .venv/bin/activate```\n",
    "\n",
    "> ```pip install -r requirements.txt```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "WyLRbAwsWSYA"
   },
   "source": [
    "### 1.3 HDF5 files\n",
    "\n",
    "Now, you'll run the *transform* function from **main.py**. For this, execute on **src** folder:\n",
    "\n",
    "> ```python main.py --source=<DATASET_NAME> --transform```\n",
    "\n",
    "Your data will be preprocess and encode, creating and saving in the **data** folder. Now your project directory will be like this:\n",
    "\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── bentham.hdf5\n",
    "│   ├── iam.hdf5\n",
    "│   ├── rimes.hdf5\n",
    "│   ├── saintgall.hdf5\n",
    "│   └── washington.hdf5\n",
    "├── raw\n",
    "│   ├── bentham\n",
    "│   │   ├── BenthamDatasetR0-GT\n",
    "│   │   └── BenthamDatasetR0-Images\n",
    "│   ├── iam\n",
    "│   │   ├── ascii\n",
    "│   │   ├── forms\n",
    "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
    "│   │   ├── lines\n",
    "│   │   └── xml\n",
    "│   ├── rimes\n",
    "│   │   ├── eval_2011\n",
    "│   │   ├── eval_2011_annotated.xml\n",
    "│   │   ├── training_2011\n",
    "│   │   └── training_2011.xml\n",
    "│   ├── saintgall\n",
    "│   │   ├── data\n",
    "│   │   ├── ground_truth\n",
    "│   │   ├── README.txt\n",
    "│   │   └── sets\n",
    "│   └── washington\n",
    "│       ├── data\n",
    "│       ├── ground_truth\n",
    "│       ├── README.txt\n",
    "│       └── sets\n",
    "└── src\n",
    "    ├── data\n",
    "    │   ├── evaluation.py\n",
    "    │   ├── generator.py\n",
    "    │   ├── preproc.py\n",
    "    │   ├── reader.py\n",
    "    │   ├── similar_error_analysis.py\n",
    "    ├── main.py\n",
    "    ├── network\n",
    "    │   ├── architecture.py\n",
    "    │   ├── layers.py\n",
    "    │   ├── model.py\n",
    "    └── tutorial.ipynb\n",
    "\n",
    "```\n",
    "\n",
    "Then upload the **data** and **src** folders in the same directory in your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "jydsAcWgWVth"
   },
   "source": [
    "## 2 Google Drive Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "wk3e7YJiXzSl"
   },
   "source": [
    "### 2.1 TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "Z7twXyNGXtbJ"
   },
   "source": [
    "Make sure the jupyter notebook is using GPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "mHw4tODULT1Z"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "UJECz8H8XVCY"
   },
   "source": [
    "Now, we'll install TensorFlow 2.0 with GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "FMg-B5PH9h3r"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-gpu==2.1.0-rc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "w5ukHtpZiz0g"
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6472fce64eb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"/device:GPU:0\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GPU device not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Found GPU at: {device_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name != \"/device:GPU:0\":\n",
    "    raise SystemError(\"GPU device not found\")\n",
    "\n",
    "print(f\"Found GPU at: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "FyMv5wyDXxqc"
   },
   "source": [
    "### 2.2 Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "P5gj6qwoX9W3"
   },
   "source": [
    "Mount your Google Drive partition.\n",
    "\n",
    "**Note:** *\\\"Colab Notebooks/handwritten-text-recognition/src/\\\"* was the directory where you put the project folders, specifically the **src** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "ACQn1iBF9k9O"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"./gdrive\", force_remount=True)\n",
    "\n",
    "%cd \"./gdrive/My Drive/Colab Notebooks/handwritten-text-recognition/src/\"\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "YwogUA8RZAyp"
   },
   "source": [
    "After mount, you can see the list os files in the project folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "-fj7fSngY1IX"
   },
   "source": [
    "## 3 Set Python Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "p6Q4cOlWhNl3"
   },
   "source": [
    "### 3.1 Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "wvqL2Eq5ZUc7"
   },
   "source": [
    "First, let's define our environment variables.\n",
    "\n",
    "Set the main configuration parameters, like input size, batch size, number of epochs and list of characters. This make compatible with **main.py** and jupyter notebook:\n",
    "\n",
    "* **dataset**: \"bentham\", \"iam\", \"rimes\", \"saintgall\", \"washington\"\n",
    "\n",
    "* **arch**: network to run: \"bluche\", \"puigcerver\", \"flor\"\n",
    "\n",
    "* **epochs**: number of epochs\n",
    "\n",
    "* **batch_size**: number size of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "_Qpr3drnGMWS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: ..\\data\\casia.hdf5\n",
      "output ..\\output\\casia\\flor\n",
      "target ..\\output\\casia\\flor\\checkpoint_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import string\n",
    "import codecs\n",
    "\n",
    "# define parameters\n",
    "source = \"casia\"\n",
    "arch = \"flor\"\n",
    "epochs = 1000\n",
    "batch_size = 16\n",
    "\n",
    "# define paths\n",
    "source_path = os.path.join(\"..\", \"data\", f\"{source}.hdf5\")\n",
    "output_path = os.path.join(\"..\", \"output\", source, arch)\n",
    "target_path = os.path.join(output_path, \"checkpoint_weights.hdf5\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# define input size, number max of chars per line and list of valid chars\n",
    "input_size = (1024, 128, 1)\n",
    "max_text_length = 128\n",
    "\n",
    "if source == 'casia':\n",
    "    content_tmp = codecs.open(\"../raw/casia/char_set.txt\", encoding='utf-8').read()\n",
    "    charset_base = \"\".join(content_tmp.split())\n",
    "else:\n",
    "    charset_base = string.printable[:95]\n",
    "\n",
    "\n",
    "print(\"source:\", source_path)\n",
    "print(\"output\", output_path)\n",
    "print(\"target\", target_path)\n",
    "#print(\"charset:\", charset_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(charset_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "BFextshOhTKr"
   },
   "source": [
    "### 3.2 DataGenerator Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "KfZ1mfvsanu1"
   },
   "source": [
    "The second class is **DataGenerator()**, responsible for:\n",
    "\n",
    "* Load the dataset partitions (train, valid, test);\n",
    "\n",
    "* Manager batchs for train/validation/test process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "8k9vpNzMIAi2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 5\n",
      "Validation images: 2\n",
      "Test images: 1\n"
     ]
    }
   ],
   "source": [
    "from data.generator import DataGenerator\n",
    "\n",
    "dtgen = DataGenerator(source=source_path,\n",
    "                      batch_size=batch_size,\n",
    "                      charset=charset_base,\n",
    "                      max_text_length=max_text_length)\n",
    "\n",
    "print(f\"Train images: {dtgen.size['train']}\")\n",
    "print(f\"Validation images: {dtgen.size['valid']}\")\n",
    "print(f\"Test images: {dtgen.size['test']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "-OdgNLK0hYAA"
   },
   "source": [
    "### 3.3 HTRModel Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "jHktk8AFcnKy"
   },
   "source": [
    "The third class is **HTRModel()**, was developed to be easy to use and to abstract the complicated flow of a HTR system. It's responsible for:\n",
    "\n",
    "* Create model with Handwritten Text Recognition flow, in which calculate the loss function by CTC and decode output to calculate the HTR metrics (CER, WER and SER);\n",
    "\n",
    "* Save and load model;\n",
    "\n",
    "* Load weights in the models (train/infer);\n",
    "\n",
    "* Make Train/Predict process using *generator*.\n",
    "\n",
    "To make a dynamic HTRModel, its parameters are the *architecture*, *input_size* and *vocab_size*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "nV0GreStISTR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1024, 128, 1)]    0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 512, 64, 16)       160       \n",
      "_________________________________________________________________\n",
      "p_re_lu_6 (PReLU)            (None, 512, 64, 16)       16        \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512, 64, 16)       112       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_5 (FullGat (None, 512, 64, 16)       4640      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 512, 64, 32)       4640      \n",
      "_________________________________________________________________\n",
      "p_re_lu_7 (PReLU)            (None, 512, 64, 32)       32        \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512, 64, 32)       224       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_6 (FullGat (None, 512, 64, 32)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 16, 40)       10280     \n",
      "_________________________________________________________________\n",
      "p_re_lu_8 (PReLU)            (None, 256, 16, 40)       40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256, 16, 40)       280       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_7 (FullGat (None, 256, 16, 40)       28880     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 16, 40)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 256, 16, 48)       17328     \n",
      "_________________________________________________________________\n",
      "p_re_lu_9 (PReLU)            (None, 256, 16, 48)       48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256, 16, 48)       336       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_8 (FullGat (None, 256, 16, 48)       41568     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 16, 48)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 128, 4, 56)        21560     \n",
      "_________________________________________________________________\n",
      "p_re_lu_10 (PReLU)           (None, 128, 4, 56)        56        \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128, 4, 56)        392       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_9 (FullGat (None, 128, 4, 56)        56560     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128, 4, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 4, 64)        32320     \n",
      "_________________________________________________________________\n",
      "p_re_lu_11 (PReLU)           (None, 128, 4, 64)        64        \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128, 4, 64)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 2, 64)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128, 256)          198144    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128, 256)          65792     \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128, 256)          296448    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128, 5992)         1539944   \n",
      "=================================================================\n",
      "Total params: 2,338,808\n",
      "Trainable params: 2,337,528\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from network.model import HTRModel\n",
    "\n",
    "# create and compile HTRModel\n",
    "# note: `learning_rate=None` will get architecture default value\n",
    "model = HTRModel(architecture=arch, input_size=input_size, vocab_size=dtgen.tokenizer.vocab_size)\n",
    "model.compile(learning_rate=0.001)\n",
    "\n",
    "# save network summary\n",
    "model.summary(output_path, \"summary.txt\")\n",
    "\n",
    "# get default callbacks and load checkpoint weights file (HDF5) if exists\n",
    "model.load_checkpoint(target=target_path)\n",
    "\n",
    "callbacks = model.get_callbacks(logdir=output_path, checkpoint=target_path, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "KASq6zqogG6Q"
   },
   "source": [
    "## 4 Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "T8eBxuoogM-d"
   },
   "source": [
    "To facilitate the visualization of the model's training, you can instantiate the Tensorboard. \n",
    "\n",
    "**Note**: All data is saved in the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "bPx4hRHuJGAd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4108838064aa850c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4108838064aa850c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --reload_interval=300 --logdir={output_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "T1fnz0Eugqru"
   },
   "source": [
    "## 5 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "w1mLOcqYgsO-"
   },
   "source": [
    "The training process is similar to the *fit()* of the Keras. After training, the information (epochs and minimum loss) is save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "2P6MSoxCISlD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1 steps, validate for 1 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 10s 10s/step\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Labels length is zero in batch 0\n\t [[node loss/dense_1_loss/CTCLoss (defined at d:\\project3\\handwritten-text-recognition\\src\\network\\model.py:254) ]] [Op:__inference_distributed_function_17974]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9b29a6ec03e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m               verbose=1)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\project3\\handwritten-text-recognition\\src\\network\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m                              \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                              \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m                              use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Labels length is zero in batch 0\n\t [[node loss/dense_1_loss/CTCLoss (defined at d:\\project3\\handwritten-text-recognition\\src\\network\\model.py:254) ]] [Op:__inference_distributed_function_17974]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "# to calculate total and average time per epoch\n",
    "epochs = 10\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "h = model.fit(x=dtgen.next_train_batch(),\n",
    "              epochs=epochs,\n",
    "              steps_per_epoch=dtgen.steps['train'],\n",
    "              validation_data=dtgen.next_valid_batch(),\n",
    "              validation_steps=dtgen.steps['valid'],\n",
    "              callbacks=callbacks,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "loss = h.history['loss']\n",
    "val_loss = h.history['val_loss']\n",
    "\n",
    "min_val_loss = min(val_loss)\n",
    "min_val_loss_i = val_loss.index(min_val_loss)\n",
    "\n",
    "time_epoch = (total_time / len(loss))\n",
    "total_item = (dtgen.size['train'] + dtgen.size['valid'])\n",
    "\n",
    "t_corpus = \"\\n\".join([\n",
    "    f\"Total train images:      {dtgen.size['train']}\",\n",
    "    f\"Total validation images: {dtgen.size['valid']}\",\n",
    "    f\"Batch:                   {dtgen.batch_size}\\n\",\n",
    "    f\"Total time:              {total_time}\",\n",
    "    f\"Time per epoch:          {time_epoch}\",\n",
    "    f\"Time per item:           {time_epoch / total_item}\\n\",\n",
    "    f\"Total epochs:            {len(loss)}\",\n",
    "    f\"Best epoch               {min_val_loss_i + 1}\\n\",\n",
    "    f\"Training loss:           {loss[min_val_loss_i]:.8f}\",\n",
    "    f\"Validation loss:         {min_val_loss:.8f}\"\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"train.txt\"), \"w\") as lg:\n",
    "    lg.write(t_corpus)\n",
    "    print(t_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "13g7tDjWgtXV"
   },
   "source": [
    "## 6 Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "ddO26OT-g_QK"
   },
   "source": [
    "The predict process is similar to the *predict* of the Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "a9iHL6tmaL_j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Predict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTC Decode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\envs\\tf2.1\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py:5811: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 792ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================ \n",
      "\n",
      "天桥的南北两侧梯道 , 仅更换主梁设计部门根据节假日最大客流无\n",
      "愫除教除瓮除织除皁除旭除厝除傕除愫除厝除傕除愫除愫除傕除愫除皁除愫除愫除黠除 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data import preproc as pp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# predict() function will return the predicts with the probabilities\n",
    "predicts, _ = model.predict(x=dtgen.next_test_batch(),\n",
    "                            steps=dtgen.steps['test'],\n",
    "                            ctc_decode=True,\n",
    "                            verbose=1)\n",
    "\n",
    "# decode to string\n",
    "predicts = [dtgen.tokenizer.decode(x[0]) for x in predicts]\n",
    "\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "# mount predict corpus file\n",
    "with open(os.path.join(output_path, \"predict.txt\"), \"w\") as lg:\n",
    "    for pd, gt in zip(predicts, dtgen.dataset['test']['gt']):\n",
    "        lg.write(f\"TE_L {gt}\\nTE_P {pd}\\n\")\n",
    "   \n",
    "for i, item in enumerate(dtgen.dataset['test']['dt'][:10]):\n",
    "    print(\"=\" * 1024, \"\\n\")\n",
    "    plt.imshow(pp.adjust_to_see(item))\n",
    "    print(dtgen.dataset['test']['gt'][i])\n",
    "    print(predicts[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "9JcAs3Q3WNJ-"
   },
   "source": [
    "## 7 Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": false,
    "id": "8LuZBRepWbom"
   },
   "source": [
    "Evaluation process is more manual process. Here we have the `ocr_metrics`, but feel free to implement other metrics instead. In the function, we have three parameters: \n",
    "\n",
    "* predicts\n",
    "* ground_truth\n",
    "* norm_accentuation (calculation with/without accentuation)\n",
    "* norm_punctuation (calculation with/without punctuation marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": null,
    "colab_type": "code",
    "collapsed": false,
    "id": "0gCwEYdKWOPK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test images:    1\n",
      "Total time:           0:00:03.072066\n",
      "Time per item:        0:00:03.072066\n",
      "\n",
      "Metrics:\n",
      "Character Error Rate: 1.00000000\n",
      "Word Error Rate:      1.00000000\n",
      "Sequence Error Rate:  1.00000000\n"
     ]
    }
   ],
   "source": [
    "from data import evaluation\n",
    "\n",
    "evaluate = evaluation.ocr_metrics(predicts=predicts,\n",
    "                                  ground_truth=dtgen.dataset['test']['gt'],\n",
    "                                  norm_accentuation=False,\n",
    "                                  norm_punctuation=False)\n",
    "\n",
    "e_corpus = \"\\n\".join([\n",
    "    f\"Total test images:    {dtgen.size['test']}\",\n",
    "    f\"Total time:           {total_time}\",\n",
    "    f\"Time per item:        {total_time / dtgen.size['test']}\\n\",\n",
    "    f\"Metrics:\",\n",
    "    f\"Character Error Rate: {evaluate[0]:.8f}\",\n",
    "    f\"Word Error Rate:      {evaluate[1]:.8f}\",\n",
    "    f\"Sequence Error Rate:  {evaluate[2]:.8f}\"\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"evaluate.txt\"), \"w\") as lg:\n",
    "    lg.write(e_corpus)\n",
    "    print(e_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "oMty1YwuWHpN"
   ],
   "name": "tutorial.ipynb",
   "provenance": null
  },
  "file_extension": ".py",
  "kernelspec": {
   "argv": [
    "c:\\ProgramData\\Anaconda3\\envs\\tf2.1\\python.exe",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "tf2.1",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "tf2.1"
  },
  "mimetype": "text/x-python",
  "name": "tutorial.ipynb",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
